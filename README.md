
# language model_hw1.ipynb
 The number of word tokens in the database.
 Vocabulary size (number of unique words) of the dataset.
 Top ten bigrams and trigrams from positive and negative review sets, including the frequencies. 
 Given a sequence of three words (w1,w2,w3), would compute the probability of the third word using trigram language model p(w3|w1,w2). If you're using log-probabilities, use base 2 for computing logs. (5 points)
 Five test cases (sequence of three words) showing output from your trigram language model. 


 # hw2_ner_pos
 shows a graph for NER and POS tag distribution on negative and positive lyrics
<img width="468" alt="image" src="https://github.com/user-attachments/assets/107997a1-7d94-471b-970f-ca03be751301">
<img width="468" alt="image" src="https://github.com/user-attachments/assets/64eddd6f-a59f-4034-88eb-834fbbf26ee6">
<img width="468" alt="image" src="https://github.com/user-attachments/assets/b934bf14-3a8a-454d-a31b-3c61504969ce">
<img width="468" alt="image" src="https://github.com/user-attachments/assets/4a4a9040-af0a-4b9d-a170-941262cf38f1">


